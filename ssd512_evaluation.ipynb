{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "826444e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_ssd512\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ssd_512\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_loss_function\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_ssd_loss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SSDLoss\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_generator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_detection_2d_data_generator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataGenerator\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meval_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maverage_precision_evaluator_test\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Evaluator\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/SWIPENet-master/data_generator/object_detection_2d_data_generator.py:27\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from models.keras_ssd512 import ssd_512\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from eval_utils.average_precision_evaluator_test import Evaluator\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43e4c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import h5py\n",
    "except ImportError:\n",
    "    warnings.warn(\"'h5py' module is missing. The fast HDF5 dataset option will be unavailable.\")\n",
    "try:\n",
    "    import json\n",
    "except ImportError:\n",
    "    warnings.warn(\"'json' module is missing. The JSON-parser will be unavailable.\")\n",
    "try:\n",
    "    from bs4 import BeautifulSoup\n",
    "except ImportError:\n",
    "    warnings.warn(\"'BeautifulSoup' module is missing. The XML-parser will be unavailable.\")\n",
    "try:\n",
    "    import pickle\n",
    "except ImportError:\n",
    "    warnings.warn(\n",
    "        \"'pickle' module is missing. You won't be able to save parsed file lists and annotations as pickled files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0b2764b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'concatenate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m modelname \u001b[38;5;129;01min\u001b[39;00m modelnames:\n\u001b[1;32m      9\u001b[0m     K\u001b[38;5;241m.\u001b[39mclear_session() \u001b[38;5;66;03m# Clear previous models from memory.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mssd_512\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43ml2_regularization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0005\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mscales\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.07\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.04\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43maspect_ratios_per_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtwo_boxes_for_ar1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moffsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mclip_boxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvariances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnormalize_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msubtract_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m117\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m104\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mswap_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mconfidence_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                    \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.45\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnms_max_output_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/SWIPENet-master/models/keras_ssd512.py:173\u001b[0m, in \u001b[0;36mssd_512\u001b[0;34m(image_size, n_classes, mode, l2_regularization, min_scale, max_scale, scales, aspect_ratios_global, aspect_ratios_per_layer, two_boxes_for_ar1, steps, offsets, clip_boxes, variances, coords, normalize_coords, subtract_mean, divide_by_stddev, swap_channels, confidence_thresh, iou_threshold, top_k, nms_max_output_size, return_predictor_sizes)\u001b[0m\n\u001b[1;32m    171\u001b[0m dilateconv6_3 \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m512\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), strides\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), dilation_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe_normal\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_regularizer\u001b[38;5;241m=\u001b[39ml2(l2_reg), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdilateconv6_3\u001b[39m\u001b[38;5;124m'\u001b[39m)(dilateconv6_2)\n\u001b[1;32m    172\u001b[0m dilateconv6_4 \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m512\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), strides\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), dilation_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe_normal\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_regularizer\u001b[38;5;241m=\u001b[39ml2(l2_reg), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdilateconv6_4\u001b[39m\u001b[38;5;124m'\u001b[39m)(dilateconv6_3)\n\u001b[0;32m--> 173\u001b[0m conv7_add \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate\u001b[49m([pool5, dilateconv6_4], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# 32  step=16\u001b[39;00m\n\u001b[1;32m    175\u001b[0m deconv1_1 \u001b[38;5;241m=\u001b[39m Conv2DTranspose(\u001b[38;5;241m512\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), strides\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe_normal\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_regularizer\u001b[38;5;241m=\u001b[39ml2(l2_reg), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeconv1_1\u001b[39m\u001b[38;5;124m'\u001b[39m)(conv7_add)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'concatenate' is not defined"
     ]
    }
   ],
   "source": [
    "img_height = 512\n",
    "img_width = 512\n",
    "n_classes = 3\n",
    "detection_mode = 'test'\n",
    "model_mode = 'inference'\n",
    "modelnames=['ssd512_2013_adam16_0.0001_time3_epoch-02_loss-10.9858_val_loss-10.1615.h5', 'ssd512_2013_adam16_0.0001_time3_epoch-01_loss-84.2419_val_loss-11.6939.h5']\n",
    "modelindex=1\n",
    "for modelname in modelnames:\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "    model = ssd_512(image_size=(img_height, img_width, 3),\n",
    "                    n_classes=n_classes,\n",
    "                    mode=model_mode,\n",
    "                    l2_regularization=0.0005,\n",
    "                    scales=[0.3, 0.15, 0.07, 0.04],\n",
    "                    aspect_ratios_per_layer=[[1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                             [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                             [1.0, 2.0, 0.5, 3.0, 1.0/3.0]],\n",
    "                    two_boxes_for_ar1=True,\n",
    "                    steps=[16, 8, 4],\n",
    "                    offsets=[0.5, 0.5, 0.5],\n",
    "                    clip_boxes=False,\n",
    "                    variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                    normalize_coords=True,\n",
    "                    subtract_mean=[123, 117, 104],\n",
    "                    swap_channels=[2, 1, 0],\n",
    "                    confidence_thresh=0.01,\n",
    "                    iou_threshold=0.45,\n",
    "                    top_k=200,\n",
    "                    nms_max_output_size=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4d7d4ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (4068919234.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [22]\u001b[0;36m\u001b[0m\n\u001b[0;31m    model.load_weights(weights_path, by_name=True)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " weights_path = '/data/deeplearn/SWEIPENet/' + modelname\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "    model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "\n",
    "    dataset = DataGenerator()\n",
    "    Pascal_VOC_dataset_images_dir = '/data/deeplearn/SWEIPENet/dataset/JPEGImages/'\n",
    "    Pascal_VOC_dataset_annotations_dir = '/data/deeplearn/SWEIPENet/dataset/Annotations/'\n",
    "    Pascal_VOC_dataset_image_set_filename = '/data/deeplearn/SWEIPENet/dataset/ImageSets/Main/test.txt'\n",
    "    classes = ['background', 'seacucumber', 'seaurchin', 'scallop']\n",
    "    dataset.parse_xml(images_dirs=[Pascal_VOC_dataset_images_dir],\n",
    "                      image_set_filenames=[Pascal_VOC_dataset_image_set_filename],\n",
    "                      annotations_dirs=[Pascal_VOC_dataset_annotations_dir],\n",
    "                      classes=classes,\n",
    "                      include_classes='all',\n",
    "                      exclude_truncated=False,\n",
    "                      exclude_difficult=False,\n",
    "                      ret=False)\n",
    "\n",
    "    evaluator = Evaluator(model=model,\n",
    "                          modelindex=modelindex,\n",
    "                          n_classes=n_classes,\n",
    "                          data_generator=dataset,\n",
    "                          model_mode=model_mode,\n",
    "                          detection_mode=detection_mode)\n",
    "    results = evaluator(img_height=img_height,\n",
    "                        img_width=img_width,\n",
    "                        batch_size=32,\n",
    "                        data_generator_mode='resize',\n",
    "                        round_confidences=False,\n",
    "                        matching_iou_threshold=0.5,\n",
    "                        border_pixels='include',\n",
    "                        sorting_algorithm='quicksort',\n",
    "                        average_precision_mode='sample',\n",
    "                        num_recall_points=11,\n",
    "                        ignore_neutral_boxes=True,\n",
    "                        return_precisions=True,\n",
    "                        return_recalls=True,\n",
    "                        return_average_precisions=True,\n",
    "                        verbose=True)\n",
    "    modelindex=modelindex+1\n",
    "print('Detection results of multiple models have been saved in /data/deeplearn/SWEIPENet/dataset/Detections/...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5531c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensembel the results of multiple models\n",
    "def intersection_area_(boxes1, boxes2, coords='corners', mode='outer_product', border_pixels='half'):\n",
    "    '''\n",
    "    The same as 'intersection_area()' but for internal use, i.e. without all the safety checks.\n",
    "    '''\n",
    "    m = boxes1.shape[0]  # The number of boxes in `boxes1`\n",
    "    n = boxes2.shape[0]  # The number of boxes in `boxes2`\n",
    "    # Set the correct coordinate indices for the respective formats.\n",
    "    if coords == 'corners':\n",
    "        xmin = 0\n",
    "        ymin = 1\n",
    "        xmax = 2\n",
    "        ymax = 3\n",
    "    elif coords == 'minmax':\n",
    "        xmin = 0\n",
    "        xmax = 1\n",
    "        ymin = 2\n",
    "        ymax = 3\n",
    "\n",
    "    if border_pixels == 'half':\n",
    "        d = 0\n",
    "    elif border_pixels == 'include':\n",
    "        d = 1  # If border pixels are supposed to belong to the bounding boxes, we have to add one pixel to any difference `xmax - xmin` or `ymax - ymin`.\n",
    "    elif border_pixels == 'exclude':\n",
    "        d = -1  # If border pixels are not supposed to belong to the bounding boxes, we have to subtract one pixel from any difference `xmax - xmin` or `ymax - ymin`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f4252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
